{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/acmoral/QuantumGenerativeBaselines/blob/master/QRBM_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r9jMfTP_z1kD"
      },
      "source": [
        "#QRBM for image reconstruction implementation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u3GewPdWz-t_"
      },
      "source": [
        "\n",
        "Universidad Nacional de Colombia \\\\\n",
        "Sergio Quiroga Sandoval squirogas@unal.edu.co\n",
        "\n",
        "\n",
        "A complete reproduction of the QRBM implemented at https://github.com/mareksubocz/QRBM, and reported in the paper [1](https://cmst.eu/articles/applying-a-quantum-annealing-based-restricted-boltzmann-machine-for-mnist-handwritten-digit-classification/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QyJQAT4Q1Gus"
      },
      "source": [
        "### Cloning repository and imports:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mhfzhNUk1LVs"
      },
      "outputs": [],
      "source": [
        "# Clone the QRBM repository\n",
        "!git clone https://github.com/mareksubocz/QRBM.git\n",
        "\n",
        "# Install everything in binder/requirements.txt\n",
        "!pip install -r QRBM/binder/requirements.txt\n",
        "\n",
        "\n",
        "import sys\n",
        "# Adjust path if you cloned somewhere else\n",
        "sys.path.append('/content/QRBM')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JitNG2W3ntl"
      },
      "outputs": [],
      "source": [
        "!pip install pyqubo      # brings in the PyQUBO library for building QUBO models :contentReference[oaicite:1]{index=1}\n",
        "!pip install dwave-tabu   # installs the TabuSampler interface (provides top-level `tabu` module) :contentReference[oaicite:2]{index=2}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rPcBs9Z80sVH"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import timeit\n",
        "import matplotlib.pyplot as plt\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "\n",
        "from qrbm.MSQRBM import MSQRBM\n",
        "from qrbm.classicalRBM import classicalRBM\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "plt.rcParams['image.cmap'] = 'gray'\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "from skimage import data, color\n",
        "from skimage.transform import rescale, resize, downscale_local_mean\n",
        "from skimage import img_as_bool\n",
        "\n",
        "import cv2 as cv\n",
        "\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-1eRyPpq3yKJ"
      },
      "source": [
        "### Dataset and image processing:"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Parameters:\n",
        "* digits: list of digits to train on\n",
        "* THRESHOLD: how bright parts of image become 1 (darker become 0)."
      ],
      "metadata": {
        "id": "XeLy5d3V_JnR"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qVJ9bpLp6Ilm"
      },
      "outputs": [],
      "source": [
        "image_height = 28\n",
        "image_width = 28\n",
        "\n",
        "# images will be flattened\n",
        "len_x = image_height * image_width\n",
        "len_y = 0\n",
        "\n",
        "digits = [0, 1]\n",
        "\n",
        "THRESHOLD = 100"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iGFqiY8x31p3"
      },
      "outputs": [],
      "source": [
        "# reading datasetn\n",
        "# 1. Install opendatasets\n",
        "!pip install opendatasets\n",
        "\n",
        "# 2. Download & unzip directly from Kaggle’s “Datasets” page\n",
        "import opendatasets as od\n",
        "od.download(\n",
        "    \"https://www.kaggle.com/oddrationale/mnist-in-csv\",\n",
        "    data_dir=\"data\"\n",
        ")  # creates data/mnist-in-csv\n",
        "\n",
        "# 3. Read CSVs\n",
        "import pandas as pd\n",
        "mnist_dataset = pd.read_csv('data/mnist-in-csv/mnist_train.csv')\n",
        "mnist_test    = pd.read_csv('data/mnist-in-csv/mnist_test.csv')\n",
        "\n",
        "\n",
        "# Train Test sets\n",
        "\n",
        "X_train = mnist_dataset.values[:,1:]\n",
        "X_train2 = mnist_dataset.values[:,:]\n",
        "\n",
        "X_test = mnist_test.values[:,1:]\n",
        "X_test2 = mnist_test.values[:,:]\n",
        "\n",
        "# print(mnist_dataset.values[:,0])\n",
        "X_train3 = []\n",
        "X_test3 = []\n",
        "\n",
        "for digit in digits:\n",
        "    X_train3.append(mnist_dataset.values[np.where(mnist_dataset.values[:,0] == digit), 1:][0])\n",
        "    X_test3.append(mnist_test.values[np.where(mnist_test.values[:,0] == digit), 1:][0])\n",
        "# X_train3 = mnist_dataset.values[np.where(mnist_dataset.values[:,0] == 0), 1:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AD3Z1C3T43es"
      },
      "outputs": [],
      "source": [
        "imgs = []\n",
        "imgs_test = []\n",
        "for digit_index in range(len(digits)):\n",
        "    imgs.append(np.resize(X_train3[digit_index], (len(X_train3[digit_index]), 28, 28)) / 255)\n",
        "    imgs_test.append(np.resize(X_test3[digit_index], (len(X_test3[digit_index]), 28, 28)) / 255)\n",
        "\n",
        "plt.imshow(imgs[0][0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Resizing, Normalizing and converting the images to binary"
      ],
      "metadata": {
        "id": "hQvCGQ468Tud"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Resizing images\n",
        "images_resized = []\n",
        "images_resized_test = []\n",
        "for digit_index in range(len(digits)):\n",
        "    images_resized.append([resize(img, (image_width, image_height), anti_aliasing=True) for img in imgs[digit_index]])\n",
        "    images_resized_test.append([resize(img, (image_width, image_height), anti_aliasing=True) for img in imgs_test[digit_index]])\n",
        "\n",
        "    # images_resized = [resize(img, (image_width, image_height), anti_aliasing=True) for img in imgs]\n",
        "\n",
        "# Normalizing images\n",
        "\n",
        "images_normalized = []\n",
        "images_normalized_test = []\n",
        "\n",
        "for digit_index in range(len(digits)):\n",
        "    images_normalized.append([cv.normalize(image_resized, image_resized, 0, 255, cv.NORM_MINMAX) for image_resized in images_resized[digit_index]])\n",
        "    images_normalized_test.append([cv.normalize(image_resized, image_resized, 0, 255, cv.NORM_MINMAX) for image_resized in images_resized_test[digit_index]])\n",
        "\n",
        "    # images_normalized = [cv.normalize(image_resized, image_resized, 0, 255, cv.NORM_MINMAX) for image_resized in images_resized]\n",
        "\n",
        "plt.imshow(images_normalized[0][0])\n",
        "plt.show()\n",
        "\n",
        "#Converting to binary\n",
        "\n",
        "data = []\n",
        "data_test = []\n",
        "for digit_index in range(len(digits)):\n",
        "    data.append([np.where(image_resized > THRESHOLD, 1, 0) for image_resized in images_resized[digit_index]])\n",
        "    data_test.append([np.where(image_resized > THRESHOLD, 1, 0) for image_resized in images_resized_test[digit_index]])\n",
        "\n",
        "# data = [np.where(image_resized > THRESHOLD, 1, 0) for image_resized in images_resized]\n",
        "\n",
        "plt.imshow(data[0][0])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "_K7JszQj8Ejc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flattening images"
      ],
      "metadata": {
        "id": "da0-f2fH8EWx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_data = []\n",
        "input_data_test = []\n",
        "for digit_index in range(len(digits)):\n",
        "    input_data.append([x.flatten().tolist() for x in data[digit_index]])\n",
        "    input_data_test.append([x.flatten().tolist() for x in data_test[digit_index]])\n",
        "\n",
        "print(input_data[0][0])"
      ],
      "metadata": {
        "id": "W_vL8DoA8p7L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_picture_tab = []\n",
        "for digit_index in range(len(digits)):\n",
        "    result_picture_tab.append(np.mean(input_data_test[digit_index], axis = 0))"
      ],
      "metadata": {
        "id": "coFPOmGJ8xfa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Shuffling training data"
      ],
      "metadata": {
        "id": "HSLfkcTL85-2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for digit in digits:\n",
        "    flat_input_data = [item for sublist in input_data for item in sublist]\n",
        "    flat_input_data_test = [item for sublist in input_data_test for item in sublist]\n",
        "\n",
        "random.shuffle(flat_input_data)\n",
        "random.shuffle(flat_input_data_test)"
      ],
      "metadata": {
        "id": "GoF6mbii8EM6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mmm8fciw0SRv"
      },
      "source": [
        "### Algorithm"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training"
      ],
      "metadata": {
        "id": "cwabPYkY82Oj"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8COvr5OV0ikR"
      },
      "source": [
        "Learning params:\n",
        "\n",
        "\n",
        "*  n_hidden: number of neurons in hidden layer.\n",
        "*   qpu: whether to use real D-wave's qpu (requires setup) or a local simulator.\n",
        "*  epochs: number of epochs.\n",
        "*  lr: learning rate.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BM Parameters\n",
        "n_hidden = 30\n",
        "qpu = False\n",
        "epochs = 1000\n",
        "lr = 0.1"
      ],
      "metadata": {
        "id": "izQiErXS-TE4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm = MSQRBM(n_visible=len_x, n_hidden=n_hidden, qpu=qpu)\n",
        "bm.image_height = image_height\n",
        "bm.tqdm = tqdm\n",
        "bm.result_picture_tab = result_picture_tab"
      ],
      "metadata": {
        "id": "QaeiY6_K8EJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bm.train(flat_input_data, len_x, len_y, epochs = epochs, lr = lr, lr_decay = 0.1)"
      ],
      "metadata": {
        "id": "Ucsk4okh8EHa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "See random sampling results"
      ],
      "metadata": {
        "id": "wRY15N0A9FqL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Generation**: \"You do not run gradient descent on a loss for your test image. Instead, you treat the RBM as a probabilistic model and sample from it via Gibbs sampling:\n",
        "\n",
        "\""
      ],
      "metadata": {
        "id": "WRP-MXt_Bu9u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for test in range(5):\n",
        "    flat_input_data_test_img = np.reshape(flat_input_data_test[test], (image_width, image_height))\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Image from test set\", y=1.03)\n",
        "    plt.imshow(flat_input_data_test_img)\n",
        "    plt.show()\n",
        "\n",
        "    generated_pic = bm.generate(test_img = flat_input_data_test[test])\n",
        "    evaluation = bm.evaluate(generated_pic, flat_input_data_test[test])\n",
        "    print(\"evaluation: \", evaluation)\n",
        "#     print(generated_pic)\n",
        "    plt.figure()\n",
        "    plt.axis('off')\n",
        "    plt.title(\"Image reconstructed after training\", y=1.03)\n",
        "    plt.imshow(np.array(generated_pic).reshape(image_height, -1))"
      ],
      "metadata": {
        "id": "VVLPnf2g8EE8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### References\n",
        "\n",
        "\n",
        "\n",
        "*  Applying a Quantum Annealing Based Restricted Boltzmann Machine for MNIST Handwritten Digit Classification [CMST paper](https://cmst.eu/articles/applying-a-quantum-annealing-based-restricted-boltzmann-machine-for-mnist-handwritten-digit-classification/)\n",
        "*  Mareksubocz github implementation from the paper: https://github.com/mareksubocz/QRBM"
      ],
      "metadata": {
        "id": "e6RCrL6sZ2A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Some Notes on the method:"
      ],
      "metadata": {
        "id": "bdYoOAVgbZy0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gibbs Sampling\n",
        "\n",
        "1. **Initialize** the visible units $$v$$ (either randomly, or to your “test” image if you’re doing a reconstruction).\n",
        "2. **Sample** each hidden unit $$h_j$$ from  \n",
        "   $$\n",
        "   p(h_j = 1 \\mid v) = \\sigma\\left(b_j + (W^\\top v)_j\\right).\n",
        "   $$\n",
        "3. **Sample** each visible unit $$v_i$$ from  \n",
        "   $$\n",
        "   p(v_i = 1 \\mid h) = \\sigma\\left(a_i + (W h)_i\\right).\n",
        "   $$\n",
        "4. **Repeat** steps 2–3 for a few (or many) iterations.  \n",
        "   Eventually your $(v, h)$ chain wanders into one of the low-energy “valleys” the model learned.\n",
        "\n",
        "> **Note:** There is no “test‐time gradient descent” on the energy surface; instead, the random updates of a Gibbs chain naturally drift toward low‐energy configurations.\n",
        "\n",
        "---\n"
      ],
      "metadata": {
        "id": "KfByrOVnbc8g"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "### Putting it all together\n",
        "\n",
        "**Train:** Adjust $(W, a, b)$ so that  $p(v) = \\frac{1}{Z} \\sum_h e^{-E(v, h)}$ puts most of its mass on your training images.\n",
        "\n",
        "**Reconstruct / Generate:**\n",
        "- *Reconstruction*  clamps the visible units initially to your test image, then does 1–2 steps of Gibbs sampling to “clean up” noise.\n",
        "- *Free generation* starts $v$ at random and runs many Gibbs steps until you land in a learned mode.\n",
        "\n",
        "**Evaluation:**  \n",
        "Once you’ve sampled your reconstructed $v$, you compare it to the original test vector (e.g., via mean-squared error).\n",
        "\n",
        "---\n",
        "Overall method:\n",
        "During training, you clamp the visible layer to each data vector and learn weights so that the hidden layer captures its correlations. During generation (or reconstruction), you sample back and forth between hidden and visible layers via Gibbs sampling—always producing your new image on the visible layer.\n",
        "\n",
        "\n",
        "Interpretation: hidden units represent features (e.g.\\ edges, strokes), not direct reconstructions. You must always sample back to the visible units to produce an actual image\n",
        "\n",
        "\n",
        "Notes Generated with ChatGPT and improved for a fast explanation of gibbs sampling and the training procedure of Boltzmann machines."
      ],
      "metadata": {
        "id": "imnbNmioCuMc"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOHjY4aMlsfFBY9plTltknx",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}